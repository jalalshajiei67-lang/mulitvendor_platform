[33m27391f6[m Update API configuration for production and add requirements.txt - Updated API base URL to use dynamic environment-based configuration - Added psycopg2-binary for PostgreSQL support - Generated requirements.txt with all dependencies
[1mdiff --git a/multivendor_platform/BATCH_REPORTING_SYSTEM.md b/multivendor_platform/BATCH_REPORTING_SYSTEM.md[m
[1mindex 6dca7c3..bbfd1ef 100644[m
[1m--- a/multivendor_platform/BATCH_REPORTING_SYSTEM.md[m
[1m+++ b/multivendor_platform/BATCH_REPORTING_SYSTEM.md[m
[36m@@ -742,3 +742,6 @@[m [mBatch Report â†’ "View All Jobs in Batch"[m
 [m
 Every scraping session now has a complete report with the option to retry only failed URLs![m
 [m
[41m+[m
[41m+[m
[41m+[m
[1mdiff --git a/multivendor_platform/README_SCRAPER.md b/multivendor_platform/README_SCRAPER.md[m
[1mindex 7ca0a0a..846551e 100644[m
[1m--- a/multivendor_platform/README_SCRAPER.md[m
[1m+++ b/multivendor_platform/README_SCRAPER.md[m
[36m@@ -115,3 +115,6 @@[m [mEvery request has:[m
 [m
 **Happy scraping!** âœ¨[m
 [m
[41m+[m
[41m+[m
[41m+[m
[1mdiff --git a/multivendor_platform/RESTART_SERVER.md b/multivendor_platform/RESTART_SERVER.md[m
[1mindex 17c4c50..9a711f5 100644[m
[1m--- a/multivendor_platform/RESTART_SERVER.md[m
[1m+++ b/multivendor_platform/RESTART_SERVER.md[m
[36m@@ -64,3 +64,6 @@[m [mYou'll see:[m
 [m
 **Restart now and the system will be fully operational!** ðŸš€[m
 [m
[41m+[m
[41m+[m
[41m+[m
[1mdiff --git a/multivendor_platform/SCRAPER_COMPLETE_SYSTEM.md b/multivendor_platform/SCRAPER_COMPLETE_SYSTEM.md[m
[1mindex d4211a3..c4a28a9 100644[m
[1m--- a/multivendor_platform/SCRAPER_COMPLETE_SYSTEM.md[m
[1m+++ b/multivendor_platform/SCRAPER_COMPLETE_SYSTEM.md[m
[36m@@ -693,3 +693,6 @@[m [mpython debug_scraper.py[m
 [m
 Start scraping and see the magic happen! âœ¨[m
 [m
[41m+[m
[41m+[m
[41m+[m
[1mdiff --git a/multivendor_platform/SCRAPER_READY_TO_USE.md b/multivendor_platform/SCRAPER_READY_TO_USE.md[m
[1mindex 860e5c8..61d6949 100644[m
[1m--- a/multivendor_platform/SCRAPER_READY_TO_USE.md[m
[1m+++ b/multivendor_platform/SCRAPER_READY_TO_USE.md[m
[36m@@ -366,3 +366,6 @@[m [mhttp://127.0.0.1:8000/admin/products/productscrapejob/add-scrape-jobs/[m
 [m
 Enjoy scraping products with batch reports and error recovery! ðŸŽ‰[m
 [m
[41m+[m
[41m+[m
[41m+[m
[1mdiff --git a/multivendor_platform/START_HERE_SCRAPER.md b/multivendor_platform/START_HERE_SCRAPER.md[m
[1mindex b4698b5..db751e4 100644[m
[1m--- a/multivendor_platform/START_HERE_SCRAPER.md[m
[1m+++ b/multivendor_platform/START_HERE_SCRAPER.md[m
[36m@@ -216,3 +216,6 @@[m [mEverything is installed, configured, and tested.[m
 [m
 **Happy scraping!** ðŸš€âœ¨[m
 [m
[41m+[m
[41m+[m
[41m+[m
[1mdiff --git a/multivendor_platform/front_end/src/services/api.js b/multivendor_platform/front_end/src/services/api.js[m
[1mindex bec8908..cb8c5fd 100644[m
[1m--- a/multivendor_platform/front_end/src/services/api.js[m
[1m+++ b/multivendor_platform/front_end/src/services/api.js[m
[36m@@ -1,8 +1,12 @@[m
 // src/services/api.js[m
 import axios from 'axios';[m
 [m
[32m+[m[32mconst API_BASE_URL = import.meta.env.PROD[m
[32m+[m[32m  ? 'https://backend.indexo.ir'[m
[32m+[m[32m  : 'http://localhost:8000';[m
[32m+[m
 const apiClient = axios.create({[m
[31m-  baseURL: 'http://127.0.0.1:8000/api',[m
[32m+[m[32m  baseURL: `${API_BASE_URL}/api`,[m
   headers: {[m
     'Content-Type': 'application/json',[m
   },[m
[1mdiff --git a/multivendor_platform/multivendor_platform/multivendor_platform/settings.py b/multivendor_platform/multivendor_platform/multivendor_platform/settings.py[m
[1mindex 5d33643..a416183 100644[m
[1m--- a/multivendor_platform/multivendor_platform/multivendor_platform/settings.py[m
[1m+++ b/multivendor_platform/multivendor_platform/multivendor_platform/settings.py[m
[36m@@ -11,7 +11,8 @@[m [mSECRET_KEY = 'your-secret-key-here'  # Make sure to set this properly[m
 # SECURITY WARNING: don't run with debug turned on in production![m
 DEBUG = True[m
 [m
[31m-ALLOWED_HOSTS = ['localhost', '127.0.0.1', '0.0.0.0'][m
[32m+[m[32m#LLOWED_HOSTS = ['localhost', '127.0.0.1', '0.0.0.0'][m
[32m+[m[32mALLOWED_HOSTS = ['backend.indexo.ir', 'indexo.ir'][m
 [m
 # Application definition[m
 INSTALLED_APPS = [[m
[36m@@ -68,11 +69,16 @@[m [mTEMPLATES = [[m
 [m
 WSGI_APPLICATION = 'multivendor_platform.wsgi.application'[m
 [m
[31m-# Database[m
[32m+[m
[32m+[m
 DATABASES = {[m
     'default': {[m
[31m-        'ENGINE': 'django.db.backends.sqlite3',[m
[31m-        'NAME': BASE_DIR / 'db.sqlite3',[m
[32m+[m[32m        'ENGINE': 'django.db.backends.postgresql',[m
[32m+[m[32m        'NAME': 'postgres',[m
[32m+[m[32m        'USER': 'postgres',[m
[32m+[m[32m        'PASSWORD': 'your_actual_password_from_connection_string',[m
[32m+[m[32m        'HOST': 'srv-captain--multivendor-db',  # matches CapRover service name[m
[32m+[m[32m        'PORT': '5432',[m
     }[m
 }[m
 [m
[1mdiff --git a/requirements.txt b/requirements.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..b04b720[m
Binary files /dev/null and b/requirements.txt differ
